{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/introduction).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["As a warm-up, you'll review some machine learning fundamentals and submit your initial results to a Kaggle competition.\n","\n","# Setup\n","\n","The questions below will give you feedback on your work. Run the following cell to set up the feedback system."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T23:59:14.254407Z","iopub.status.busy":"2022-10-25T23:59:14.252933Z","iopub.status.idle":"2022-10-25T23:59:14.263691Z","shell.execute_reply":"2022-10-25T23:59:14.261557Z","shell.execute_reply.started":"2022-10-25T23:59:14.254351Z"},"trusted":true},"outputs":[],"source":["# Set up code checking\n","import os\n","# if not os.path.exists(\"../input/train.csv\"):\n","#     os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n","#     os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\")  \n","# from learntools.core import binder\n","# binder.bind(globals())\n","# from learntools.ml_intermediate.ex1 import *\n","# print(\"Setup Complete\")"]},{"cell_type":"markdown","metadata":{},"source":["You will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course) to predict home prices in Iowa using 79 explanatory variables describing (almost) every aspect of the homes.  \n","\n","![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n","\n","Run the next code cell without changes to load the training and validation features in `X_train` and `X_valid`, along with the prediction targets in `y_train` and `y_valid`.  The test features are loaded in `X_test`.  (_If you need to review **features** and **prediction targets**, please check out [this short tutorial](https://www.kaggle.com/dansbecker/your-first-machine-learning-model).  To read about model **validation**, look [here](https://www.kaggle.com/dansbecker/model-validation).  Alternatively, if you'd prefer to look through a full course to review all of these topics, start [here](https://www.kaggle.com/learn/machine-learning).)_"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-10-26T00:02:01.076857Z","iopub.status.busy":"2022-10-26T00:02:01.076349Z","iopub.status.idle":"2022-10-26T00:02:01.141904Z","shell.execute_reply":"2022-10-26T00:02:01.140808Z","shell.execute_reply.started":"2022-10-26T00:02:01.076818Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/ops/code/kaggle_ml\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# print the cwd\n","print(os.getcwd())\n","\n","# Read the data\n","X_full = pd.read_csv('./input/iowa-housing/train.csv', index_col='Id')\n","X_test_full = pd.read_csv('./input/iowa-housing/test.csv', index_col='Id')\n","\n","# Obtain target and predictors\n","y = X_full.SalePrice\n","features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n","X = X_full[features].copy()\n","X_test = X_test_full[features].copy()\n","\n","# Break off validation set from training data\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["Use the next cell to print the first several rows of the data. It's a nice way to get an overview of the data you will use in your price prediction model."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-10-26T00:02:05.501446Z","iopub.status.busy":"2022-10-26T00:02:05.500978Z","iopub.status.idle":"2022-10-26T00:02:05.526491Z","shell.execute_reply":"2022-10-26T00:02:05.525093Z","shell.execute_reply.started":"2022-10-26T00:02:05.501409Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>YearBuilt</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>FullBath</th>\n","      <th>BedroomAbvGr</th>\n","      <th>TotRmsAbvGrd</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>619</th>\n","      <td>11694</td>\n","      <td>2007</td>\n","      <td>1828</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>871</th>\n","      <td>6600</td>\n","      <td>1962</td>\n","      <td>894</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>13360</td>\n","      <td>1921</td>\n","      <td>964</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>13265</td>\n","      <td>2002</td>\n","      <td>1689</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>303</th>\n","      <td>13704</td>\n","      <td>2001</td>\n","      <td>1541</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n","Id                                                                    \n","619    11694       2007      1828         0         2             3   \n","871     6600       1962       894         0         1             2   \n","93     13360       1921       964         0         1             2   \n","818    13265       2002      1689         0         2             3   \n","303    13704       2001      1541         0         2             3   \n","\n","     TotRmsAbvGrd  \n","Id                 \n","619             9  \n","871             5  \n","93              5  \n","818             7  \n","303             6  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["The next code cell defines five different random forest models.  Run this code cell without changes.  (_To review **random forests**, look [here](https://www.kaggle.com/dansbecker/random-forests)._)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","# Define the models\n","model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n","model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n","# model_2.9 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0, max_depth=7, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n","model_3 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n","model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n","model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n","model_6 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, random_state=0)\n","model_7 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, max_features=0.5, random_state=0)\n","model_8 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, random_state=0)\n","model_9 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, random_state=0)\n","model_10 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, min_samples_leaf=5, random_state=0)  \n","model_11 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, min_samples_leaf=5, bootstrap=False, random_state=0) \n","model_12 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n","model_13 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, random_state=0)\n","model_14 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, random_state=0)\n","model_15 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, random_state=0)\n","model_16 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, random_state=0)\n","model_17 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, min_samples_leaf=5, random_state=0)\n","model_18 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, max_leaf_nodes=10, min_samples_leaf=5, bootstrap=False, random_state=0)\n","model_19 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, min_samples_leaf=5,max_features='sqrt', bootstrap=False, random_state=0)\n","model_20 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, min_samples_leaf=5,max_features='log2', bootstrap=False, random_state=0)\n","model_21 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0, max_depth=7, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n","\n","\n","models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11, model_12, model_13, model_14, model_15, model_16, model_17, model_18, model_19, model_20, model_21]"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","# Define the models\n","model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n","model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n","model_3 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n","model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n","model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n","model_6 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, random_state=0)\n","model_7 = RandomForestRegressor(n_estimators=100, max_depth=7, min_samples_split=20, max_features=0.5, random_state=0)\n","model_8 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, random_state=0)\n","model_9 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, random_state=0)\n","model_10 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', max_depth=7, min_samples_split=20, max_features=0.5, random_state=0)\n","\n","\n","models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10]"]},{"cell_type":"markdown","metadata":{},"source":["To select the best model out of the five, we define a function `score_model()` below.  This function returns the mean absolute error (MAE) from the validation set.  Recall that the best model will obtain the lowest MAE.  (_To review **mean absolute error**, look [here](https://www.kaggle.com/dansbecker/model-validation).)_\n","\n","Run the code cell without changes."]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model 1 MAE: 24015\n","Model 2 MAE: 23740\n","Model 3 MAE: 23528\n","Model 4 MAE: 23996\n","Model 5 MAE: 23706\n","Model 6 MAE: 23986\n","Model 7 MAE: 25247\n","Model 8 MAE: 23496\n","Model 9 MAE: 24278\n","Model 10 MAE: 25335\n"]}],"source":["from sklearn.metrics import mean_absolute_error\n","\n","# Function for comparing different models\n","def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n","    model.fit(X_t, y_t)\n","    preds = model.predict(X_v)\n","    return mean_absolute_error(y_v, preds)\n","\n","# create a dictionary to store the results: mae_results*\n","mae_results = []\n","\n","for i in range(0, len(models)):\n","    mae = score_model(models[i])\n","    print(\"Model %d MAE: %d\" % (i+1, mae))\n","\n","    # append the mae to the dictionary*\n","    mae_results.append(mae) \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Step 1: Evaluate several models\n","\n","Use the above results to fill in the line below.  Which model is the best model?  Your answer should be one of `model_1`, `model_2`, `model_3`, `model_4`, or `model_5`."]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["min mae_results: 23496\n","best model index: 13\n","best model: RandomForestRegressor(criterion='absolute_error', max_depth=7, random_state=0)\n"]}],"source":["# find the min of mae_results\n","min_mae_results = min(mae_results)\n","\n","# print min mae_results\n","print(\"min mae_results: %d\" % min_mae_results)\n","\n","# find index of min mae_results or best model\n","best_model_index = mae_results.index(min_mae_results)+1\n","\n","# print best model index    \n","print(\"best model index: %d\" % best_model_index)\n","\n","# get the best model from models list\n","best_model = models[best_model_index-1]\n","\n","print(\"best model: %s\" % best_model)\n","\n","# make best_model equals the word model_ concatenated with index of best model\n","# best_model = \"model_\" + str(best_model_index)\n","# print(best_model)\n","\n","\n","# Check your answer\n","# step_1.check()"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#step_1.hint()\n","#step_1.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Generate test predictions\n","\n","Great. You know how to evaluate what makes an accurate model. Now it's time to go through the modeling process and make predictions. In the line below, create a Random Forest model with the variable name `my_model`."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RandomForestRegressor(criterion='absolute_error', random_state=0)\n"]}],"source":["# Define a model\n","my_model = best_model\n","# print my model \n","print(my_model)\n","\n","# Check your answer\n","# step_2.check()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#step_2.hint()\n","#step_2.solution()"]},{"cell_type":"markdown","metadata":{},"source":["Run the next code cell without changes.  The code fits the model to the training and validation data, and then generates test predictions that are saved to a CSV file.  These test predictions can be submitted directly to the competition!"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# Fit the model to the training data\n","my_model.fit(X, y)\n","\n","# Generate test predictions\n","preds_test = my_model.predict(X_test)\n","\n","# Save predictions in format used for competition scoring\n","output = pd.DataFrame({'Id': X_test.index,\n","                       'SalePrice': preds_test})\n","output.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m output\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# visualize data with seaborn graph pr plot\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# plot the data\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["output.head(10)\n","\n","# visualize data with a graph \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# set the style of the graph\n","sns.set_style('whitegrid')\n","\n","# set the size of the graph\n","plt.figure(figsize=(10, 6))\n","\n","# create a scatter plot of the data\n","plt.scatter(X_train['LotArea'], y_train, color='blue', label='Training Data')\n","plt.scatter(X_valid['LotArea'], y_valid, color='red', label='Validation Data')\n","\n","# set the title of the graph\n","plt.title('LotArea vs SalePrice')\n","\n","# set the x and y labels\n","plt.xlabel('LotArea')\n","plt.ylabel('SalePrice')\n","\n","# set the legend\n","plt.legend()\n","\n","# show the graph\n","plt.show()\n","\n","\n","# visulize predictions with a graph\n","# set the style of the graph\n","sns.set_style('whitegrid')\n","\n","# set the size of the graph\n","plt.figure(figsize=(10, 6))\n","\n","# create a scatter plot of the data\n","plt.scatter(X_train['LotArea'], y_train, color='blue', label='Training Data')\n","plt.scatter(X_valid['LotArea'], y_valid, color='red', label='Validation Data')\n","\n","# create a scatter plot of the predictions\n","plt.scatter(X_valid['LotArea'], preds_valid, color='green', label='Predictions')\n","\n","# set the title of the graph\n","plt.title('LotArea vs SalePrice')\n","\n","# set the x and y labels\n","plt.xlabel('LotArea')\n","plt.ylabel('SalePrice')\n","\n","# set the legend\n","plt.legend()\n","\n","# show the graph\n","plt.show()\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'xgboost'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# vizualize the results with xgboost\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# create a DMatrix for training data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dtrain \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(X_train, label\u001b[39m=\u001b[39my_train)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"]}],"source":["# vizualize the results with xgboost\n","import xgboost as xgb\n","\n","# create a DMatrix for training data\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","\n","# create a DMatrix for validation data\n","dvalid = xgb.DMatrix(X_valid, label=y_valid)\n","\n","# create a DMatrix for test data\n","dtest = xgb.DMatrix(X_test)\n","\n","# create a watchlist\n","watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n","# set the parameters\n","params = {'min_child_weight': 1, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 5,\n","            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n","            'eval_metric': 'mae', 'objective': 'reg:linear'}\n","\n","# train the model\n","model = xgb.train(params, dtrain, 400, watchlist, early_stopping_rounds=50,\n","                    maximize=False, verbose_eval=10)\n","\n","# make predictions\n","xgb_preds = model.predict(dtest)\n","\n","# reurn the mean absolute error mae for the model\n","mae = mean_absolute_error(y_valid, model.predict(dvalid))\n","print(\"Mean Absolute Error: \" + str(mae))\n","\n","\n","\n","# save the predictions\n","output = pd.DataFrame({'Id': X_test.index,\n","                          'SalePrice': xgb_preds})\n","output.to_csv('xgboost_submission.csv', index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Submit your results\n","\n","Once you have successfully completed Step 2, you're ready to submit your results to the leaderboard!  First, you'll need to join the competition if you haven't already.  So open a new window by clicking on [this link](https://www.kaggle.com/c/home-data-for-ml-course).  Then click on the **Join Competition** button.  _(If you see a \"Submit Predictions\" button instead of a \"Join Competition\" button, you have already joined the competition, and don't need to do so again.)_\n","\n","Next, follow the instructions below:\n","1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n","2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n","3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n","4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n","\n","You have now successfully submitted to the competition!\n","\n","If you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n"]},{"cell_type":"markdown","metadata":{},"source":["# Keep going\n","\n","You've made your first model. But how can you quickly make it better?\n","\n","Learn how to improve your competition results by incorporating columns with **[missing values](https://www.kaggle.com/alexisbcook/missing-values)**."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intermediate-machine-learning/discussion) to chat with other learners.*"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('sklearn-env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"ac22767284fa7de9951c43376386eb73cd5359e83d2496301849b7d38304da64"}}},"nbformat":4,"nbformat_minor":4}
